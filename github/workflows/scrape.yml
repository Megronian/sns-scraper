name: Daily SNS Scraping

on:
  schedule:
    # æ¯æ—¥åˆå‰9æ™‚ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰ã«å®Ÿè¡Œ
    - cron: '0 0 * * *'
  workflow_dispatch: # æ‰‹å‹•å®Ÿè¡Œãƒœã‚¿ãƒ³ã‚‚è¿½åŠ 

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆ
      uses: actions/checkout@v4
    
    - name: Pythonç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œ
      run: python scraper.py
    
    - name: çµæœã‚’GitHubã«ä¿å­˜
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/posts.json
        git diff --staged --quiet || git commit -m "ğŸ“Š æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿æ›´æ–° $(date '+%Y-%m-%d %H:%M:%S')"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
